{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User Data :\n",
      "shape :  (943, 5)\n",
      "   user_id  age sex  occupation zip_code\n",
      "0        1   24   M  technician    85711\n",
      "1        2   53   F       other    94043\n",
      "2        3   23   M      writer    32067\n",
      "3        4   24   M  technician    43537\n",
      "4        5   33   F       other    15213\n",
      "\n",
      "Ratings Data :\n",
      "shape :  (100000, 4)\n",
      "   user_id  movie_id  rating  unix_timestamp\n",
      "0      196       242       3       881250949\n",
      "1      186       302       3       891717742\n",
      "2       22       377       1       878887116\n",
      "3      244        51       2       880606923\n",
      "4      166       346       1       886397596\n",
      "\n",
      "Item Data :\n",
      "shape :  (1682, 24)\n",
      "   movie id        movie title release date  video release date  \\\n",
      "0         1   Toy Story (1995)  01-Jan-1995                 NaN   \n",
      "1         2   GoldenEye (1995)  01-Jan-1995                 NaN   \n",
      "2         3  Four Rooms (1995)  01-Jan-1995                 NaN   \n",
      "3         4  Get Shorty (1995)  01-Jan-1995                 NaN   \n",
      "4         5     Copycat (1995)  01-Jan-1995                 NaN   \n",
      "\n",
      "                                            IMDb URL  unknown  Action  \\\n",
      "0  http://us.imdb.com/M/title-exact?Toy%20Story%2...        0       0   \n",
      "1  http://us.imdb.com/M/title-exact?GoldenEye%20(...        0       1   \n",
      "2  http://us.imdb.com/M/title-exact?Four%20Rooms%...        0       0   \n",
      "3  http://us.imdb.com/M/title-exact?Get%20Shorty%...        0       1   \n",
      "4  http://us.imdb.com/M/title-exact?Copycat%20(1995)        0       0   \n",
      "\n",
      "   Adventure  Animation  Children's  ...  Fantasy  Film-Noir  Horror  Musical  \\\n",
      "0          0          1           1  ...        0          0       0        0   \n",
      "1          1          0           0  ...        0          0       0        0   \n",
      "2          0          0           0  ...        0          0       0        0   \n",
      "3          0          0           0  ...        0          0       0        0   \n",
      "4          0          0           0  ...        0          0       0        0   \n",
      "\n",
      "   Mystery  Romance  Sci-Fi  Thriller  War  Western  \n",
      "0        0        0       0         0    0        0  \n",
      "1        0        0       0         1    0        0  \n",
      "2        0        0       0         1    0        0  \n",
      "3        0        0       0         0    0        0  \n",
      "4        0        0       0         1    0        0  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# pass in column names for each CSV as the column name is not given in the file and read them using pandas.\n",
    "# You can check the column names from the readme file\n",
    "\n",
    "# reading users file:\n",
    "u_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
    "users_df = pd.read_csv('/mnt/d/Study/Analytics Vidhya/AV-Recommendation Engine/ml-100k/u.user', sep='|', names=u_cols,encoding='latin-1')\n",
    "\n",
    "# reading ratings file:\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "ratings_df = pd.read_csv('/mnt/d/Study/Analytics Vidhya/AV-Recommendation Engine/ml-100k/u.data', sep='\\t', names=r_cols,encoding='latin-1')\n",
    "\n",
    "# reading items file:\n",
    "i_cols = ['movie id', 'movie title' ,'release date','video release date', 'IMDb URL', 'unknown', 'Action', 'Adventure',\n",
    "'Animation', 'Children\\'s', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy',\n",
    "'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n",
    "items_df = pd.read_csv('/mnt/d/Study/Analytics Vidhya/AV-Recommendation Engine/ml-100k/u.item', sep='|', names=i_cols,\n",
    "encoding='latin-1')\n",
    "\n",
    "\n",
    "\n",
    "# After loading the dataset, we should look at the content of each file (users, ratings, items).\n",
    "\n",
    "# Looking at the user file\n",
    "print(\"\\nUser Data :\")\n",
    "print(\"shape : \", users_df.shape)\n",
    "print(users_df.head())\n",
    "\n",
    "# We have 943 users in the dataset and each user has 5 features, i.e. user_ID, age, sex, occupation and zip_code. Now letâ€™s look at the ratings file.\n",
    "\n",
    "# Ratings Data\n",
    "print(\"\\nRatings Data :\")\n",
    "print(\"shape : \", ratings_df.shape)\n",
    "print(ratings_df.head())\n",
    "\n",
    "# We have 100k ratings for different user and movie combinations. Now finally examine the items file.\n",
    "\n",
    "# Item Data\n",
    "print(\"\\nItem Data :\")\n",
    "print(\"shape : \", items_df.shape)\n",
    "print(items_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext(\"local\", \"App Name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "\n",
    "sql = SQLContext(sc)\n",
    "#sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.setCheckpointDir('checkpoint/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = sql.createDataFrame(ratings_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
      "+-------+--------+------+--------------+\n",
      "|user_id|movie_id|rating|unix_timestamp|\n",
      "+-------+--------+------+--------------+\n",
      "|    196|     242|     3|     881250949|\n",
      "|    186|     302|     3|     891717742|\n",
      "|     22|     377|     1|     878887116|\n",
      "|    244|      51|     2|     880606923|\n",
      "|    166|     346|     1|     886397596|\n",
      "|    298|     474|     4|     884182806|\n",
      "|    115|     265|     2|     881171488|\n",
      "|    253|     465|     5|     891628467|\n",
      "|    305|     451|     3|     886324817|\n",
      "|      6|      86|     3|     883603013|\n",
      "|     62|     257|     2|     879372434|\n",
      "|    286|    1014|     5|     879781125|\n",
      "|    200|     222|     5|     876042340|\n",
      "|    210|      40|     3|     891035994|\n",
      "|    224|      29|     3|     888104457|\n",
      "|    303|     785|     3|     879485318|\n",
      "|    122|     387|     5|     879270459|\n",
      "|    194|     274|     2|     879539794|\n",
      "|    291|    1042|     4|     874834944|\n",
      "|    234|    1184|     2|     892079237|\n",
      "+-------+--------+------+--------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Look at the column names\n",
    "print(ratings.columns)\n",
    "\n",
    "# Look at the first few rows of data\n",
    "print(ratings.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ratings dataframe is  93.70% empty.\n"
     ]
    }
   ],
   "source": [
    "# Count the total number of ratings in the dataset\n",
    "numerator = ratings.select(\"rating\").count()\n",
    "\n",
    "# Count the number of distinct userIds and distinct movieIds\n",
    "num_users = ratings.select(\"user_id\").distinct().count()\n",
    "num_movies = ratings.select(\"movie_id\").distinct().count()\n",
    "\n",
    "# Set the denominator equal to the number of users multiplied by the number of movies\n",
    "denominator = num_users * num_movies\n",
    "\n",
    "# Divide the numerator by the denominator\n",
    "sparsity = (1.0 - (numerator *1.0)/denominator)*100\n",
    "print(\"The ratings dataframe is \", \"%.2f\" % sparsity + \"% empty.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+------+--------------+\n",
      "|user_id|movie_id|rating|unix_timestamp|\n",
      "+-------+--------+------+--------------+\n",
      "|    196|     242|     3|     881250949|\n",
      "|    186|     302|     3|     891717742|\n",
      "|     22|     377|     1|     878887116|\n",
      "|    244|      51|     2|     880606923|\n",
      "|    166|     346|     1|     886397596|\n",
      "|    298|     474|     4|     884182806|\n",
      "|    115|     265|     2|     881171488|\n",
      "|    253|     465|     5|     891628467|\n",
      "|    305|     451|     3|     886324817|\n",
      "|      6|      86|     3|     883603013|\n",
      "|     62|     257|     2|     879372434|\n",
      "|    286|    1014|     5|     879781125|\n",
      "|    200|     222|     5|     876042340|\n",
      "|    210|      40|     3|     891035994|\n",
      "|    224|      29|     3|     888104457|\n",
      "|    303|     785|     3|     879485318|\n",
      "|    122|     387|     5|     879270459|\n",
      "|    194|     274|     2|     879539794|\n",
      "|    291|    1042|     4|     874834944|\n",
      "|    234|    1184|     2|     892079237|\n",
      "+-------+--------+------+--------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------+--------+------+--------------+\n",
      "|user_id|movie_id|rating|unix_timestamp|\n",
      "+-------+--------+------+--------------+\n",
      "|     22|     377|     1|     878887116|\n",
      "|      6|      86|     3|     883603013|\n",
      "|     62|     257|     2|     879372434|\n",
      "|     95|     546|     2|     879196566|\n",
      "|     38|      95|     5|     892430094|\n",
      "|     63|     277|     4|     875747401|\n",
      "|     50|     246|     3|     877052329|\n",
      "|     97|     194|     3|     884238860|\n",
      "|      7|      32|     4|     891350932|\n",
      "|     10|      16|     4|     877888877|\n",
      "|     99|       4|     5|     886519097|\n",
      "|     81|     432|     2|     876535131|\n",
      "|     25|     181|     5|     885853415|\n",
      "|     59|     196|     5|     888205088|\n",
      "|     72|     679|     2|     880037164|\n",
      "|     87|     384|     4|     879877127|\n",
      "|     42|     423|     5|     881107687|\n",
      "|     20|     288|     1|     879667584|\n",
      "|     13|     526|     3|     882141053|\n",
      "|     60|     427|     5|     883326620|\n",
      "+-------+--------+------+--------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------+-----+\n",
      "|user_id|count|\n",
      "+-------+-----+\n",
      "|     26|  107|\n",
      "|     29|   34|\n",
      "|    474|  327|\n",
      "|    191|   27|\n",
      "|     65|   80|\n",
      "|    418|   20|\n",
      "|    541|  133|\n",
      "|    558|   20|\n",
      "|    293|  388|\n",
      "|    222|  387|\n",
      "|    270|  138|\n",
      "|    730|   38|\n",
      "|    938|  108|\n",
      "|    278|   23|\n",
      "|    243|   81|\n",
      "|    367|   58|\n",
      "|    442|  143|\n",
      "|    705|  114|\n",
      "|    720|   30|\n",
      "|     19|   20|\n",
      "+-------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the requisite packages\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# View the ratings dataset\n",
    "ratings.show()\n",
    "\n",
    "# Filter to show only userIds less than 100\n",
    "ratings.filter(col(\"user_id\") < 100).show()\n",
    "\n",
    "# Group data by userId, count ratings\n",
    "ratings.groupBy(\"user_id\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Min num ratings for movies\n",
    "print(\"Movie with the fewest ratings: \")\n",
    "ratings.groupBy(\"movie_id\").count().select(min(\"count\")).show()\n",
    "\n",
    "# Avg num ratings per movie\n",
    "print(\"Avg num ratings per movie: \")\n",
    "ratings.groupBy(\"movie_id\").count().select(avg(\"count\")).show()\n",
    "\n",
    "# Min num ratings for user\n",
    "print(\"User with the fewest ratings: \")\n",
    "ratings.groupBy(\"user_id\").count().select(min(\"count\")).show()\n",
    "\n",
    "# Avg num ratings per users\n",
    "print(\"Avg num ratings per user: \")\n",
    "ratings.groupBy(\"user_id\").count().select(avg(\"count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: long (nullable = true)\n",
      " |-- movie_id: long (nullable = true)\n",
      " |-- rating: long (nullable = true)\n",
      " |-- unix_timestamp: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use .printSchema() to see the datatypes of the ratings dataset\n",
    "ratings.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- movie_id: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Tell Spark to convert the columns to the proper data types\n",
    "ratings = ratings.select(ratings.user_id.cast(\"integer\"), ratings.movie_id.cast(\"integer\"), ratings.rating.cast(\"double\"))\n",
    "\n",
    "# Call .printSchema() again to confirm the columns are now in the correct format\n",
    "ratings.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.ml.recommendation.ALS"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the required functions\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "# Create test and train set\n",
    "(train, test) = ratings.randomSplit([0.8, 0.2], seed = 1234)\n",
    "\n",
    "# Create ALS model\n",
    "als = ALS(userCol=\"user_id\", itemCol=\"movie_id\", ratingCol=\"rating\", nonnegative = True,coldStartStrategy= \"drop\", implicitPrefs = False)\n",
    "\n",
    "# Confirm that a model called \"als\" was created\n",
    "type(als)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#als = ALS(userCol=\"user_id\", itemCol=\"movie_id\", ratingCol=\"rating\",rank =25, maxIter = 100, regParam = 0.5, nonnegative = True,coldStartStrategy= \"drop\", implicitPrefs = False)\n",
    "\n",
    "#model=als.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num models to be tested:  2\n"
     ]
    }
   ],
   "source": [
    "# Add hyperparameters and their respective values to param_grid\n",
    "param_grid = ParamGridBuilder() \\\n",
    "            .addGrid(als.rank, [10, 50, ]) \\\n",
    "            .addGrid(als.maxIter, [50]) \\\n",
    "            .addGrid(als.regParam, [.05]) \\\n",
    "            .build()\n",
    "           \n",
    "# Define evaluator as RMSE and print length of evaluator\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol\n",
    "=\"prediction\") \n",
    "print (\"Num models to be tested: \", len(param_grid))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrossValidator_32fd7436c0e7\n"
     ]
    }
   ],
   "source": [
    "# Build cross validation using CrossValidator\n",
    "cv = CrossValidator(estimator=als, estimatorParamMaps=param_grid, evaluator=evaluator, numFolds=5)\n",
    "\n",
    "# Confirm cv was built\n",
    "print(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit cross validator to the 'train' dataset\n",
    "model = cv.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract best model from the cv model above\n",
    "best_model = model.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method HasPredictionCol.getPredictionCol of ALSModel: uid=ALS_b78242419c46, rank=50>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.getPredictionCol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = best_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+------+----------+\n",
      "|user_id|movie_id|rating|prediction|\n",
      "+-------+--------+------+----------+\n",
      "|    601|     148|   3.0|   2.61434|\n",
      "|    330|     148|   4.0|  4.318637|\n",
      "|    727|     148|   2.0| 3.5162623|\n",
      "|    190|     148|   4.0| 3.2469242|\n",
      "|    297|     148|   3.0| 2.3736668|\n",
      "|    178|     148|   4.0| 3.6291234|\n",
      "|    328|     148|   3.0| 2.9313915|\n",
      "|    923|     148|   4.0| 3.9039102|\n",
      "|    552|     148|   3.0| 2.5907874|\n",
      "|    423|     148|   3.0| 2.5433755|\n",
      "|    757|     148|   4.0| 2.7531908|\n",
      "|     51|     148|   3.0| 2.9523456|\n",
      "|    438|     148|   5.0|  4.086958|\n",
      "|    706|     148|   4.0| 2.8821194|\n",
      "|    361|     148|   1.0| 2.4361029|\n",
      "|    181|     148|   2.0| 1.9416219|\n",
      "|    249|     148|   3.0| 3.2219837|\n",
      "|    893|     148|   3.0| 3.2738438|\n",
      "|    203|     148|   3.0| 3.3258357|\n",
      "|    690|     148|   3.0| 2.7949307|\n",
      "+-------+--------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "0.9406700180002333\n"
     ]
    }
   ],
   "source": [
    "# View the predictions \n",
    "test_predictions.show()\n",
    "\n",
    "# Calculate and print the RMSE of test_predictions\n",
    "RMSE = evaluator.evaluate(test_predictions)\n",
    "print(RMSE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
